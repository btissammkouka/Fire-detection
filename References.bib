
@article{noauthor_httpsieeexploreieeeorgdocument10973447_nodate,
	title = {https://ieeexplore.ieee.org/document/10973447},
}

@misc{xu_light-yolov5_2022,
	title = {Light-{YOLOv}5: A Lightweight Algorithm for Improved {YOLOv}5 in Complex Fire Scenarios},
	url = {http://arxiv.org/abs/2208.13422},
	doi = {10.48550/arXiv.2208.13422},
	shorttitle = {Light-{YOLOv}5},
	abstract = {Fire-detection technology is of great importance for successful fire-prevention measures. Image-based fire detection is one effective method. At present, object-detection algorithms are deficient in performing detection speed and accuracy tasks when they are applied in complex fire scenarios. In this study, a lightweight fire-detection algorithm, Light-{YOLOv}5 (You Only Look Once version five), is presented. First, a separable vision transformer ({SepViT}) block is used to replace several C3 modules in the final layer of a backbone network to enhance both the contact of the backbone network to global in-formation and the extraction of flame and smoke features; second, a light bidirectional feature pyramid network (Light-{BiFPN}) is designed to lighten the model while improving the feature extraction and balancing speed and accuracy features during a fire-detection procedure; third, a global attention mechanism ({GAM}) is fused into the network to cause the model to focus more on the global dimensional features and further improve the detection accuracy of the model; and finally, the Mish activation function and {SIoU} loss are utilized to simultaneously increase the convergence speed and enhance the accuracy. The experimental results show that compared to the original algorithm, the mean average accuracy ({mAP}) of Light-{YOLOv}5 increases by 3.3\%, the number of parameters decreases by 27.1\%, and the floating point operations ({FLOPs}) decrease by 19.1\%. The detection speed reaches 91.1 {FPS}, which can detect targets in complex fire scenarios in real time.},
	number = {{arXiv}:2208.13422},
	publisher = {{arXiv}},
	author = {Xu, Hao and Li, Bo and Zhong, Fei},
	urldate = {2025-06-01},
	date = {2022-12-01},
	eprinttype = {arxiv},
	eprint = {2208.13422 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text PDF:/home/btissam/Zotero/storage/PVK7X8H2/Xu et al. - 2022 - Light-YOLOv5 A Lightweight Algorithm for Improved YOLOv5 in Complex Fire Scenarios.pdf:application/pdf;Snapshot:/home/btissam/Zotero/storage/6E8PR6IS/2208.html:text/html},
}

@misc{islam_fire_2023,
	title = {Fire Detection From Image and Video Using {YOLOv}5},
	url = {http://arxiv.org/abs/2310.06351},
	doi = {10.48550/arXiv.2310.06351},
	abstract = {For the detection of fire-like targets in indoor, outdoor and forest fire images, as well as fire detection under different natural lights, an improved {YOLOv}5 fire detection deep learning algorithm is proposed. The {YOLOv}5 detection model expands the feature extraction network from three dimensions, which enhances feature propagation of fire small targets identification, improves network performance, and reduces model parameters. Furthermore, through the promotion of the feature pyramid, the top-performing prediction box is obtained. Fire-{YOLOv}5 attains excellent results compared to state-of-the-art object detection networks, notably in the detection of small targets of fire and smoke with {mAP} 90.5\% and f1 score 88\%. Overall, the Fire-{YOLOv}5 detection model can effectively deal with the inspection of small fire targets, as well as fire-like and smoke-like objects with F1 score 0.88. When the input image size is 416 x 416 resolution, the average detection time is 0.12 s per frame, which can provide real-time forest fire detection. Moreover, the algorithm proposed in this paper can also be applied to small target detection under other complicated situations. The proposed system shows an improved approach in all fire detection metrics such as precision, recall, and mean average precision.},
	number = {{arXiv}:2310.06351},
	publisher = {{arXiv}},
	author = {Islam, Arafat and Habib, Md Imtiaz},
	urldate = {2025-06-01},
	date = {2023-10-10},
	eprinttype = {arxiv},
	eprint = {2310.06351 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text PDF:/home/btissam/Zotero/storage/3ECNIAFH/Islam and Habib - 2023 - Fire Detection From Image and Video Using YOLOv5.pdf:application/pdf;Snapshot:/home/btissam/Zotero/storage/IXFDSMG4/2310.html:text/html},
}

@article{yar_modified_2023,
	title = {A modified {YOLOv}5 architecture for efficient fire detection in smart cities},
	volume = {231},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417423009673},
	doi = {10.1016/j.eswa.2023.120465},
	abstract = {Fire disasters are considered to be among the most harmful hazards, causing fatalities, ecological and economic chaos, property damage, and they can even impact climate change. Early fire detection is necessary to overcome these losses and disruption. Fire detection using vision sensors is a promising research area that has gained significant attention from computer vision experts. Traditionally, low-level colour features were used for fire detection but they have now been superseded by effective deep learning models that achieve higher accuracy. However, these models also suffer from a higher false alarm rate, due to the fact that they treat fire detection as a classification task where the entire image is classified into a single class and the region of the proposal stage is ignored. Furthermore, the time complexity and model size limit these models from real-world implementation. To overcome these challenges, we propose a modified {YOLOv}5s model that integrates a Stem module in the backbone, replaces larger kernels with smaller ones in the {SPP} (Neck), and adds the P6 module into the head. This model achieves promising results with lower complexity and smaller model size, and is able to detect both small and large fire regions in images. Moreover, we contribute a medium-scale fire dataset that consists of three classes (i.e. vehicle fire, building fire, and indoor electric fire), with manual annotation according to the object detection model, where the dataset is publicly available for the research purposes. Finally, for fair evaluation, we re-implement 12 different state-of-the-art object detection models, including the proposed model, and trained them over a self-created dataset. We found that the proposed model achieved better detection performance and applicable in real-world scenario. Our codes and dataset is publicly available at https://github.com/Hikmat-Yar/Modified-{YOLOv}5-Code.},
	pages = {120465},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Yar, Hikmat and Khan, Zulfiqar Ahmad and Ullah, Fath U Min and Ullah, Waseem and Baik, Sung Wook},
	urldate = {2025-06-01},
	date = {2023-11-30},
	keywords = {Building fire, Disaster management, Fire detection, Forest fire, Smart city, Surveillance system, Vehicle fire},
	file = {ScienceDirect Snapshot:/home/btissam/Zotero/storage/ZUHJUTXN/S0957417423009673.html:text/html},
}

@article{he_wildfire_2023,
	title = {Wildfire detection for transmission line based on improved lightweight {YOLO}},
	volume = {9},
	issn = {2352-4847},
	url = {https://www.sciencedirect.com/science/article/pii/S2352484722023708},
	doi = {10.1016/j.egyr.2022.10.435},
	series = {2022 9th International Conference on Power and Energy Systems Engineering},
	abstract = {Wildfires in transmission line passages are a severe threat to power security. Two wildfire detection models, which are based on the {YOLOv}5, are proposed in this paper. Due to the limited computing power of embedded terminals, the proposed models simplify the network structure of {YOLOv}5. Specifically, one is that only the overall structure of the neck and head parts in the original network structure is simplified, and the second method is based on the first method to delete the modules of backbone, which greatly reduces the number of parameters of the model. The experimental results show that the proposed lightweight models can achieve real-time monitoring in embedded devices while the accuracy and recall remain high.},
	pages = {512--520},
	journaltitle = {Energy Reports},
	shortjournal = {Energy Reports},
	author = {He, Hui and Zhang, Zheng and Jia, Qiang and Huang, Lei and Cheng, Yongqiang and Chen, Bo},
	urldate = {2025-06-01},
	date = {2023-03-01},
	keywords = {Embedded terminal, {FPS}, {GFLOPs}, Lightweight model, Wildfire detection, {YOLOv}5},
	file = {ScienceDirect Snapshot:/home/btissam/Zotero/storage/XAHVWTNS/S2352484722023708.html:text/html},
}

@article{he_wildfire_2023-1,
	title = {Wildfire detection for transmission line based on improved lightweight {YOLO}},
	volume = {9},
	issn = {23524847},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352484722023708},
	doi = {10.1016/j.egyr.2022.10.435},
	abstract = {Wildfires in transmission line passages are a severe threat to power security. Two wildfire detection models, which are based on the {YOLOv}5, are proposed in this paper. Due to the limited computing power of embedded terminals, the proposed models simplify the network structure of {YOLOv}5. Specifically, one is that only the overall structure of the neck and head parts in the original network structure is simplified, and the second method is based on the first method to delete the modules of backbone, which greatly reduces the number of parameters of the model. The experimental results show that the proposed lightweight models can achieve real-time monitoring in embedded devices while the accuracy and recall remain high.},
	pages = {512--520},
	journaltitle = {Energy Reports},
	shortjournal = {Energy Reports},
	author = {He, Hui and Zhang, Zheng and Jia, Qiang and Huang, Lei and Cheng, Yongqiang and Chen, Bo},
	urldate = {2025-06-01},
	date = {2023-03},
	langid = {english},
	file = {PDF:/home/btissam/Zotero/storage/Q7HQ9FNZ/He et al. - 2023 - Wildfire detection for transmission line based on improved lightweight YOLO.pdf:application/pdf},
}

@online{noauthor_computer_nodate,
	title = {Computer vision based fire detection in color images {\textbar} Request {PDF}},
	url = {https://www.researchgate.net/publication/224493976_Computer_vision_based_fire_detection_in_color_images},
	urldate = {2025-06-01},
}
